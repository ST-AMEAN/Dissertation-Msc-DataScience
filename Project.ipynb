{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de8c0b1",
   "metadata": {},
   "source": [
    "# Data visualisation and Forecasting \n",
    "### London's AirBnB and Rentals data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7e40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5f529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"paper\", font_scale = 2)\n",
    "sns.axes_style({ 'xtick.direction': 'out', 'ytick.direction': 'out',})\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1233bfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.12.1)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Downloading numpy-1.26.2-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.1.1)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.42.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth, tensorboard-data-server, protobuf, numpy, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, ml-dtypes, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.25.2 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 numpy-1.26.2 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\st22712\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\st22712\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\st22712\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\st22712\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.2 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.2 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.25.2 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.25.2 which is incompatible.\n",
      "google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.25.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4bd08",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a789f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\st22712\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f91444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "Airbnb_path = 'm:/pc/desktop/Project/Airbnb_Listing.csv'\n",
    "Rental_path = 'm:/pc/desktop/Project/Rental_Price.csv'\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "Airbnb_df = pd.read_csv(Airbnb_path)\n",
    "Rental_df = pd.read_csv(Rental_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6f4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GeoJSON file path\n",
    "geojson_path = 'm:/pc/desktop/Project/neighbourhoods.geojson'\n",
    "# Load the GeoJSON file into a GeoPandas GeoDataFrame\n",
    "neighbourhoods_gdf = gpd.read_file(geojson_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3dcfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Borough Bedroom.Category  Count_of_listing   Mean  \\\n",
      "0  Barking and Dagenham        1 Bedroom                50   67.0   \n",
      "1  Barking and Dagenham       2 Bedrooms                20  134.0   \n",
      "2  Barking and Dagenham       3 Bedrooms                 0  139.0   \n",
      "3  Barking and Dagenham           Studio                 0   90.0   \n",
      "4                Barnet        1 Bedroom               160   79.0   \n",
      "\n",
      "   Lower_quartile  Median  Upper_quartile  Annual_OCC  \n",
      "0            39.0    56.0            94.0   26.889873  \n",
      "1           102.0   125.0           180.0   23.067101  \n",
      "2           124.0   152.0           152.0   22.270553  \n",
      "3            90.0    90.0            90.0   10.655738  \n",
      "4            47.0    68.0            96.0   28.392099  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(Airbnb_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b698ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Borough Bedroom.Category  Count.of.rents  Mean  \\\n",
      "0  Barking and Dagenham           Studio              10   779   \n",
      "1  Barking and Dagenham        1 Bedroom             200  1046   \n",
      "2  Barking and Dagenham       2 Bedrooms             340  1266   \n",
      "3  Barking and Dagenham       3 Bedrooms             240  1505   \n",
      "4                Barnet           Studio             110   962   \n",
      "\n",
      "   Lower.quartile  Median  Upper.quartile  \n",
      "0             750     750             850  \n",
      "1             950    1050            1100  \n",
      "2            1200    1250            1350  \n",
      "3            1400    1500            1600  \n",
      "4             850     950            1050  \n"
     ]
    }
   ],
   "source": [
    "print(Rental_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5909b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Borough           126 non-null    object \n",
      " 1   Bedroom.Category  126 non-null    object \n",
      " 2   Count_of_listing  126 non-null    int64  \n",
      " 3   Mean              125 non-null    float64\n",
      " 4   Lower_quartile    125 non-null    float64\n",
      " 5   Median            125 non-null    float64\n",
      " 6   Upper_quartile    125 non-null    float64\n",
      " 7   Annual_OCC        126 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 8.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Airbnb_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b3146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131 entries, 0 to 130\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Borough           131 non-null    object\n",
      " 1   Bedroom.Category  131 non-null    object\n",
      " 2   Count.of.rents    131 non-null    int64 \n",
      " 3   Mean              131 non-null    int64 \n",
      " 4   Lower.quartile    131 non-null    int64 \n",
      " 5   Median            131 non-null    int64 \n",
      " 6   Upper.quartile    131 non-null    int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 7.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Rental_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4947baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   neighbourhood        33 non-null     object  \n",
      " 1   neighbourhood_group  0 non-null      object  \n",
      " 2   geometry             33 non-null     geometry\n",
      "dtypes: geometry(1), object(2)\n",
      "memory usage: 920.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "neighbourhoods_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7e05e",
   "metadata": {},
   "source": [
    "neighbourhood_group is full of NaNs. So we can probably get rid of those columns. We can check what other columns are completely full of NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b559a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_columns(df):\n",
    "    \"\"\"\n",
    "        Return the column names where all their data is NaN from a dataframe\n",
    "    \"\"\"\n",
    "    nan_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().all():\n",
    "            nan_cols.append(col)\n",
    "    return nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce48fd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neighbourhood_group']\n"
     ]
    }
   ],
   "source": [
    "neighbourhood_nans = get_nan_columns(neighbourhoods_gdf)\n",
    "print(f\"{neighbourhood_nans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a352c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_gdf.drop(neighbourhood_nans, inplace=True, axis=1)\n",
    "neighbourhoods_gdf = neighbourhoods_gdf.set_index(\"neighbourhood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b572ef0",
   "metadata": {},
   "source": [
    "Add statistics data to the neighbourhood_gdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_gdf[\"price_mean\"] = listings_df.groupby(\"neighbourhood_cleansed\")[\"price_numeric\"].mean()\n",
    "neighbourhoods_gdf[\"price_std\"] = listings_df.groupby(\"neighbourhood_cleansed\")[\"price_numeric\"].std()\n",
    "neighbourhoods_gdf[\"price_median\"] = listings_df.groupby(\"neighbourhood_cleansed\")[\"price_numeric\"].median()\n",
    "neighbourhoods_gdf[\"price_mode\"] = listings_df.groupby(\"neighbourhood_cleansed\")[\"price_numeric\"].agg(pd.Series.mode)\n",
    "neighbourhoods_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods_gdf[\"centre\"] = neighbourhoods_gdf[\"geometry\"].centroid;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eda4ac",
   "metadata": {},
   "source": [
    "Plot the mean price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc831b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c310d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c6652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de37e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d1215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbfe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf19c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7e9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
